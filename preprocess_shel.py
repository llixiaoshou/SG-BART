python new_preprocess.py -train_src ../dataset/text-data/train_src50.txt -train_tgt ../dataset/text-data/train_tgt50.txt -valid_src ../dataset/text-data/dev_src50.txt -valid_tgt ../dataset/text-data/dev_tgt50.txt -train_ans ../dataset/text-data/train_answer50.txt -valid_ans ../dataset/text-data/dev_answer50.txt -train_graph ../dataset/json-data/train_edges.json -valid_graph ../dataset/json-data/valid_edges.json -node_feature -copy -answer -save_sequence_data ../dataset/preprocessed-data/preprcessed_sequence_data.pt -save_graph_data ../dataset/preprocessed-data/preprcessed_graph_data.pt -train_dataset ../dataset/Datasets/train_dataset.pt -valid_dataset ../dataset/Datasets/valid_dataset.pt -src_seq_length 200 -tgt_seq_length 50 -src_vocab_size 50000 -tgt_vocab_size 50000 -src_words_min_frequency 3 -tgt_words_min_frequency 2 -vocab_trunc_mode frequency -pre_trained_vocab ../dataset/glove/glove.840B.300d.txt -word_vec_size 300 -batch_size 32